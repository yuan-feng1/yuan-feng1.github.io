<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Yuan Feng</title>
    <link>https://yuan-feng1.github.io/project/</link>
    <description>Recent content in Projects on Yuan Feng</description>
    <generator>Source Themes academia (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 16 Nov 2020 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://yuan-feng1.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Deep Learning - Insects Classification</title>
      <link>https://yuan-feng1.github.io/project/hw7/</link>
      <pubDate>Mon, 16 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yuan-feng1.github.io/project/hw7/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;./0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;introduction-to-cnn&#34;&gt;Introduction to CNN&lt;/h2&gt;
&lt;p&gt;A convolutional neural network (CNN) is a specific type of artificial neural network that uses perceptrons, a machine learning unit algorithm, for supervised learning, to analyze data. CNNs apply to image processing, natural language processing and other kinds of cognitive tasks. They are also the go-to deep learning architecture for computer vision tasks, such as object detection, image segmentation, facial recognition, etc.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;image-classification&#34;&gt;Image Classification&lt;/h2&gt;
&lt;p&gt;Image classification is one of popular use-case for CNN. In this hands-on tutorial, we will leverage Keras, a python based deep learning framework to build the CNN model to classify the type of insects from &lt;a href=&#34;https://www.insectimages.org/index.cfm&#34;&gt;insect images&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Classification is the process of categorizing images based on their features. Theses feature are usually represented by the significant edges in an image, the level of pixel density, the different pixel values, etc. With regard to the insect dataset, the shapes and edges of insects could be different, the colors in pixels values may also vary, and these indicators may help indentify the specific insect images, and we hope to find thses specific pattern across these images by converting them into matrices of pixel values and further feed these data into deep learning models.&lt;/p&gt;
&lt;p&gt;One example of this preprocessing is shown below. After converting the images into matrices of pixels, we could construct the original image with the following code, which will return the first image in train dataset.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt.imshow&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;X_train&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0&lt;span style=&#34;color:#f92672&#34;&gt;][&lt;/span&gt;:,:,::-1&lt;span style=&#34;color:#f92672&#34;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                                                 Figure 1 - Image of Dragonfly
&lt;/code&gt;&lt;/pre&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;img src=&#34;./0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;components-in-cnn&#34;&gt;Components in CNN&lt;/h2&gt;
&lt;p&gt;The workflow is as follows: For each input image in CNN models, it will pass it through a series of convolution layers with filters (Kernals), then the Pooling process, then will pass through fully connected layers (FC) and lastly, apply Softmax function to classify an object, and return the probabilistic values between 0 and 1.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Convolution&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A convolution is a mathematical operation applied on a matrix. This matrix is usually the image represented in the form of pixels/numbers. The convolution operation extracts the features from the image.
&lt;img src=&#34;./1.gif&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                                                 Figure 2 - Convolution Example
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Padding&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Padding is simply a process of adding layers of zeros to our input images so as to avoid the problems mentioned above. This prevents shrinking as, if p = number of layers of zeros added to the border of the image, then our (n x n) image becomes (n + 2p) x (n + 2p) image after padding&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ReLu layer&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The importance of ReLU is to introduce non-linearity in our CNN model. This is an element-wise operation (applied per pixel) which will replaces all negative pixel values by 0 in the feature map. Convolution is a linear operation – element wise matrix multiplication and addition, so we account for non-linearity by introducing a non-linear function like ReLU.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pooling&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The reason why we introduce Spatial Pooling (also called subsampling or downsampling) is that it will reduce the dimensionality of each feature map but retains the most important information. Spatial Pooling can be of different types: Max, Average, Sum etc. In case of Max Pooling, we define a spatial neighborhood (for example, a 2×2 window) and take the largest element from the rectified feature map within that window. In cases of Average Pooling, we could take the average values, and in case of sum pooling, we will use the sum of all elements in that window. In practice, Max Pooling has been shown to perform the best.
&lt;img src=&#34;./5.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                                                     Figure 2 - Pooling Example
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Fully connected layer&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Then we will flatten the output of the last ReLu layer. (Flattening means we convert it to a vector.) The vector values are then connected to all neurons in the fully connected layer. When the model is able to detect higher level features in the input images, it can then function as an input for a fully connected layer.
&lt;img src=&#34;./6.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                                                     Figure 2 - Fully connected layer Example
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;code-implementation&#34;&gt;Code Implementation&lt;/h2&gt;
&lt;p&gt;Below is the Python keras inplementation of using the insects dataset to classify the type of insects. After pre-processing mentioned previously, we then construct the CNN model and fit the train dataset into the model. Here I use 50 epochs and batch size of 64, and as shown in the screenshot, the accuracy kept increasing as the training proceed.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;  keras.models.Sequential&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Conv2D&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;32, &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;5, 5&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=(&lt;/span&gt;84,84,3&lt;span style=&#34;color:#f92672&#34;&gt;)))&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;MaxPooling2D&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;pool_size&lt;span style=&#34;color:#f92672&#34;&gt;=(&lt;/span&gt;2, 2&lt;span style=&#34;color:#f92672&#34;&gt;)))&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Conv2D&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;32, &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;5, 5&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;))&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;MaxPooling2D&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;pool_size&lt;span style=&#34;color:#f92672&#34;&gt;=(&lt;/span&gt;2, 2&lt;span style=&#34;color:#f92672&#34;&gt;)))&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Flatten&lt;span style=&#34;color:#f92672&#34;&gt;())&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Dense&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;1000, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;))&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Dropout&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;0.5&lt;span style=&#34;color:#f92672&#34;&gt;))&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Dense&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;500, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;))&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Dropout&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;0.5&lt;span style=&#34;color:#f92672&#34;&gt;))&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Dense&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;250, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;))&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Dense&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;10, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./3.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Then after the training is completed, the model will be compiled and fit on train dataset. The accuracy on test data is 0.73 and loss is 1.60. These are not optimal as of now, there may be overfitting issues, which could be fixed by further tuning the model and using cross-validation techniques in the future.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;model.compile&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;
              loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;categorical_crossentropy&amp;#39;&lt;/span&gt;,
              metrics&lt;span style=&#34;color:#f92672&#34;&gt;=[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;])&lt;/span&gt;
model.fit&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;X_train, y_train, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;50, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;64&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
test_loss, test_acc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model.evaluate&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;X_test, y_test&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./4.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;sources&#34;&gt;Sources&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://cs231n.github.io/convolutional-networks/&#34;&gt;Convolutional Neural Networks (CNNs / ConvNets)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/&#34;&gt;An Intuitive Explanation of Convolutional Neural Networks&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dahsboard on US PHD Recipients</title>
      <link>https://yuan-feng1.github.io/project/hw6/</link>
      <pubDate>Wed, 04 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yuan-feng1.github.io/project/hw6/</guid>
      <description>&lt;h2 id=&#34;phd-in-us&#34;&gt;PHD in US&lt;/h2&gt;
&lt;p&gt;This dataset comes from &lt;a href=&#34;https://ncses.nsf.gov/pubs/nsf19301/survey-description&#34;&gt;PhDs awarded in the US&lt;/a&gt;. It collects data on the number and characteristics of individuals receiving research doctoral degrees from U.S. academic institutions. Based on its official website, this survey included surveys from individuals receiving a research doctorate from a U.S. academic institutions in various fields.&lt;/p&gt;
&lt;h2 id=&#34;dash--plotly&#34;&gt;Dash &amp;amp; Plotly&lt;/h2&gt;
&lt;p&gt;Dash is a Open Source Python library for creating reactive, Web-based applications. Dash is a user interface library for creating analytical web applications. Those who use Python for data analysis, data exploration, visualization, modelling, instrument control, and reporting will find immediate use for Dash.&lt;/p&gt;
&lt;h2 id=&#34;analysis&#34;&gt;Analysis&lt;/h2&gt;
&lt;p&gt;Online dashboard can be found &lt;a href=&#34;http://noafeng72.pythonanywhere.com&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;There are three plots included in this Dashboard. I included screenshots in this post. For the interactive version.
Dashboard here](&lt;a href=&#34;http://noafeng72.pythonanywhere.com&#34;&gt;http://noafeng72.pythonanywhere.com&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./d3.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;This table illustrates the median salary of PHDs in 2017. As we could see, there is a quite large between different fields. The salaries in Math &amp;amp; CS are higher than the rest of areas overall sectors, and PHDs who work in the industry have higher salaries than rest of sectors overall.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./d2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;This table illustrates the debt situation of PHDs from 2008 to 2017. The majority of PHDs have no debts, while there are significant number of PHDs who have quite high debts (over 30,000 USD) in their course of PHD study. Based on this graph, the financial situation of PHDs is overall stable.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./d1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;This table illustrates the number of PHDs recipients from 2008 to 2017. We can see from the plot for each field, the number of PHDs recipients are increasing. To be more specific, the area of life sciences has the biggest increase, this is a sign of scientific focus of the US society in life science areas such as healthcare.
Overall, the number of PHDs recipients and this trend is seemingly to maintain, I can estimate that there will be more PHDs in the following years.&lt;/p&gt;
&lt;h2 id=&#34;dash-code&#34;&gt;Dash Code&lt;/h2&gt;
&lt;p&gt;Overall, the code style in Dash is similar to other plotting packages. There are plenty of tutorials on plotly official website for Python implementation of Dash. Following is a part of my full code, that calls the part of figure and place them onto the the dashboard.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;app.layout &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; html.Div&lt;span style=&#34;color:#f92672&#34;&gt;([&lt;/span&gt;
    html.H1&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;children&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Dashboard on Science &amp;amp; Engineering Doctorates&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;,
    dcc.Graph&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;id&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;fig22&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;,
    dcc.Graph&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;
        id&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bar1&amp;#39;&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;,
    dcc.Slider&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;
        id&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;year1&amp;#39;&lt;/span&gt;,
        min&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;2008,
        max&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;2017,
        value&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;2008,
        marks&lt;span style=&#34;color:#f92672&#34;&gt;={&lt;/span&gt;str&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;year&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;: str&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;year&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; year in year_unique&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;,
        step&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None
    &lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;,
    dcc.Graph&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;
        id&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Number of Doctorate recipients 1987 - 2007&amp;#39;&lt;/span&gt;,
        figure&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;fig11
    &lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;deployment&#34;&gt;Deployment&lt;/h2&gt;
&lt;p&gt;One easy approach is to use:&lt;a href=&#34;https://www.pythonanywhere.com/&#34;&gt;pythonanywhere&lt;/a&gt;. I followed &lt;a href=&#34;https://towardsdatascience.com/the-easiest-way-to-deploy-your-dash-app-for-free-f92c575bb69e&#34;&gt;this&lt;/a&gt; introduction on Medium.&lt;/p&gt;
&lt;p&gt;First, we need to sign up to pythonanywhere.com by creating a Beginner account. On the top bar go to Web &amp;gt; Add a new web app, the select Flask as the Python Web framework. You need to choose the version of Python that works best for your peoject.&lt;/p&gt;
&lt;p&gt;The next step is uploading the python file. On the top bar go to Files and, in the Directories sidebar, click on mysite/. You&amp;rsquo;ll find a file named flask_app.py inside. You can delete the default empty python file.&lt;/p&gt;
&lt;p&gt;The third step is to install the dependencies. On the Consoles tap, we’ll find the Bash console, this is the same as well as the Python console. Then we can start uploading the files we generated.&lt;/p&gt;
&lt;p&gt;Last step is to change the code in Web and in the Code section after opening the WSGI configuration file based on your code and board implementation.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./s.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Star Wars Data with Request</title>
      <link>https://yuan-feng1.github.io/project/hw5/</link>
      <pubDate>Thu, 15 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yuan-feng1.github.io/project/hw5/</guid>
      <description>&lt;h2 id=&#34;star-wars-api--request&#34;&gt;Star Wars API &amp;amp; Request&lt;/h2&gt;
&lt;p&gt;Requests is one of the most popular libraries that helps retrieve data from the Internet. I will utilize the Star Wars API, which includes information about all characters from Stsr Wars, and Request to collect online data in Python and perform data wrangling and analysis.&lt;/p&gt;
&lt;h2 id=&#34;loading-data-with-request&#34;&gt;Loading Data with Request&lt;/h2&gt;
&lt;h2 id=&#34;heading&#34;&gt;&lt;/h2&gt;
&lt;h2 id=&#34;heading-1&#34;&gt;&lt;/h2&gt;
&lt;p&gt;First, we take a look at Request and download the data of the first person in the database. By giving the link of first person and convert the returned values to json format, we successfully retrieved information about Luke Skywalker.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;import requests
one &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; requests.get&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://swapi.dev/api/people/1&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
char &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; one.json&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt;
char
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./1.jpg&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Notice that the API only returns the information in the current page passed in the request function. In order to retrieve all characters from database, a for loop that iterates over all non-empty pages will be applied.&lt;/p&gt;
&lt;h2 id=&#34;heading-2&#34;&gt;&lt;/h2&gt;
&lt;h2 id=&#34;heading-3&#34;&gt;&lt;/h2&gt;
&lt;h2 id=&#34;heading-4&#34;&gt;&lt;/h2&gt;
&lt;h2 id=&#34;heading-5&#34;&gt;&lt;/h2&gt;
&lt;h2 id=&#34;getting-all-characters-from-star-wars&#34;&gt;Getting All Characters from Star Wars&lt;/h2&gt;
&lt;h2 id=&#34;heading-6&#34;&gt;&lt;/h2&gt;
&lt;h2 id=&#34;heading-7&#34;&gt;&lt;/h2&gt;
&lt;p&gt;The following code shows how to download the information about each person and then transform into a complete list.&lt;/p&gt;
&lt;p&gt;By initiating an empty list and a pending the results of each request to that list, You&amp;rsquo;ll be able to get an entire list of all people appeared in the Star Wars API.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;
instance  &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; requests.get&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;https://swapi.dev/api/people/&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
all &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; instance.json&lt;span style=&#34;color:#f92672&#34;&gt;()[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;next&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;:
    all &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; instance.json&lt;span style=&#34;color:#f92672&#34;&gt;()[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;results&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
    instance &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; requests.get&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;instance.json&lt;span style=&#34;color:#f92672&#34;&gt;()[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;next&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;])&lt;/span&gt;

all &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; instance.json&lt;span style=&#34;color:#f92672&#34;&gt;()[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;results&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In order to better understand the retrieved information, I transformed the J some format into a panda dataframe using the &amp;ldquo;json_normalize&amp;rdquo; function. Below a preview of what the date it looks like.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;import pandas as pd

df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd.json_normalize&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;all&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
df.head&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./4.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;query-to-find-the-oldest&#34;&gt;Query to Find the Oldest&lt;/h2&gt;
&lt;h2 id=&#34;heading-8&#34;&gt;&lt;/h2&gt;
&lt;h2 id=&#34;heading-9&#34;&gt;&lt;/h2&gt;
&lt;p&gt;Perfect! Now that we have the data set, we can go ahead and start some interesting analysis. Here we hope to find the name of the oldest person.&lt;/p&gt;
&lt;p&gt;In the world of Star Wars, the way they record the time is by ABY or BBY, which means “After Battle of Yavin” / “Before Battle of Yavin”. We do not need to worry about this, because all people in our dataset are classified as BBY.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;birth &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;birth_year&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
import numpy as np
birth &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; birth.str.replace&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;BBY&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;.replace&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;unknown&amp;#39;&lt;/span&gt;,0&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;.astype&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
df&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;age&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; birth
df.sort_values&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;by&lt;span style=&#34;color:#f92672&#34;&gt;=[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;, ascending&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;.head&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;1&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then we could do a simple data cleaning by removing the BBY in the &amp;ldquo;age&amp;rdquo; columnm, transform string formatted numbers into double, and replace missing values with 0.Lastly, by performing a sort on the age column in a descending fashion, you&amp;rsquo;ll get the line of the olderst person - Yoda! that explains why he is so wise.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./5.jpg&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;what-movies-does-he-appear-in&#34;&gt;What Movies Does He Appear in?&lt;/h2&gt;
&lt;h2 id=&#34;heading-10&#34;&gt;&lt;/h2&gt;
&lt;h2 id=&#34;heading-11&#34;&gt;&lt;/h2&gt;
&lt;p&gt;Now that we have Yoda, As somebody who has never watch Star Wars movies before, I am really interested in finding out what movies he appeared in. However, our current dataset only shows a list of available urls to retrieve the films information. So we need to construct a for loop, and then use request to get the title from the information retrieved using these URLs.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;films &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;x &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x in df.sort_values&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;by&lt;span style=&#34;color:#f92672&#34;&gt;=[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;, ascending&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;.head&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;1&lt;span style=&#34;color:#f92672&#34;&gt;)[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;films&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]][&lt;/span&gt;0&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
film_names &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;requests.get&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;i&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;.json&lt;span style=&#34;color:#f92672&#34;&gt;()[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;title&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i in films&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
film_names
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;I also concatenated all the responses into a list. We can see that Yoda appeared in The Empire Strikes Back, Return of the Jedi, The Phantom Menace, Attack of the Clones, and Revenge of the Sith.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./3.jpg&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;If you want to find out more about the process in detail. Here is detailed process ans source code on my &lt;a href=&#34;https://github.com/yuan-feng1/bios-823-2019/blob/master/HW5.ipynb&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Spotify Song Database</title>
      <link>https://yuan-feng1.github.io/project/hw4/</link>
      <pubDate>Fri, 09 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yuan-feng1.github.io/project/hw4/</guid>
      <description>&lt;h2 id=&#34;spotify-songs-data&#34;&gt;Spotify Songs Data&lt;/h2&gt;
&lt;p&gt;Understanding and managing data is one of the priorities of analysts and data scientists. Relational databases are common and useful tools for performing tasks in selected database. Both querying and building databases are essential functionaries of relational databases. This post will focus on constructing databases in SQL with data from &lt;a href=&#34;https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-01-21/readme.md&#34;&gt;Spotify songs&lt;/a&gt;. Various information including track name, album name and track characteristics are provided in this dataset. Analysis will be also performed on the intrumentalness of songs in playlists.&lt;/p&gt;
&lt;h2 id=&#34;database-basics&#34;&gt;Database Basics&lt;/h2&gt;
&lt;p&gt;In order for databased to run efficiently, normalization is a common technique to reduce redundancy in storaging the information.  Normalization derives the relationships of contents and stores the dataset in separate tables.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;First Normal Form (1NF)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is the basic requirement for database efficiency where we require four must-have features: Each column name is unique; Atomic values in each cell; The values in one column should belong to one type and the order does not matter.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Second Normal Form (2NF)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We then come to Second Normal Form where there are more requirements based on 1NF: Now no partial dependency is allowed. It means that there cannot be dependencies other than the Primary Key, which is a set of values that could uniquely identify a record. And we must find each value based on the complete Primary Key.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Third Normal Form (3NF)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In 3NF, besides 1NF and 2NF requirements, we are not allowed to have transitive dependencies: Non-Primary Key columns in the data cannot contain information about the rest of columns.&lt;/p&gt;
&lt;h2 id=&#34;our-schema&#34;&gt;Our Schema&lt;/h2&gt;
&lt;p&gt;If we know the track ID, we could find its name, release date and artist. And based on the track name, we will then find about album name, album release date, etc. Therefore, the best schema is to separate them into different tables to achieve Third Normal Form:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Table&lt;/th&gt;
&lt;th&gt;Columns Included&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;track_id_playlist_id&lt;/td&gt;
&lt;td&gt;Track ID and Playlist ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;track_id_album_id&lt;/td&gt;
&lt;td&gt;Track ID and Album ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;playlist_id_album_id&lt;/td&gt;
&lt;td&gt;Playlist ID and Album ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;album_id_album_name&lt;/td&gt;
&lt;td&gt;Album ID and Album Name&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;album_id_album_date&lt;/td&gt;
&lt;td&gt;Album ID and Release Date&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;playlist_id_name&lt;/td&gt;
&lt;td&gt;Playlist ID and Name&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;playlist_id_genre&lt;/td&gt;
&lt;td&gt;Playlist ID and Genre&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;playlist_id_subgenre&lt;/td&gt;
&lt;td&gt;Playlist ID and Subgenre&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;track_id_track_name&lt;/td&gt;
&lt;td&gt;Track ID and Track names&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;track_id_track_artist&lt;/td&gt;
&lt;td&gt;Track ID and artist names&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;track_id_more_details&lt;/td&gt;
&lt;td&gt;Track ID and other features&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;database-constrcution&#34;&gt;Database Constrcution&lt;/h2&gt;
&lt;p&gt;With the help of SQLite, database construction is now an easy process, we can connect to the server using just a few lines of code and upload dataframes directly into the created database:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;%load_ext sql
%sql sqlite://
%sql PERSIST track_id_album_id;
%sql PERSIST track_id_playlist_id;
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here is detailed process ans source code on my &lt;a href=&#34;https://github.com/yuan-feng1/bios-823-2019/blob/master/Yuan_Feng_HW4.ipynb&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;database-test-run&#34;&gt;Database Test Run&lt;/h2&gt;
&lt;p&gt;We can test the functionality of the database by running some queries to solve a question of our interest. Here we want to see find the names of all playlists that contain instrumentals.&lt;/p&gt;
&lt;p&gt;Based on the data dictionary, we know songs with &amp;ldquo;instrumentals&amp;rdquo; bigger than .5 are qualified for this question. To find the names of such playlists, we need information from
&amp;ldquo;track_id_playlist_id&amp;rdquo;, &amp;ldquo;track_id_more_details&amp;rdquo; and &amp;ldquo;playlist_id_name&amp;rdquo;. The following code first selects playlist ID that has instrumental songs and saves as temporary table, then join the &amp;ldquo;playlist_name&amp;rdquo; table to find the names corresponding with these track IDs.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;%%sql 
create table temp as
&lt;span style=&#34;color:#66d9ef&#34;&gt;select&lt;/span&gt; distinct&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;p.playlist_id&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
from track_id_playlist_id as p 
left join track_id_more_details as t
on t.track_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; p.track_id
where t.instrumentalness &amp;gt; 0.5;

&lt;span style=&#34;color:#66d9ef&#34;&gt;select&lt;/span&gt; distinct&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;p.playlist_name&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
from temp
left join playlist_id_name as p 
on p.playlist_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; temp.playlist_id

DROP TABLE IF EXISTS temp;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now our database is successfully implemented! As we could see below, the code will return a list of all playlists that contain instrumentals, which means it&amp;rsquo;s running as expected:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./res.jpg&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Visualizing Malaria Death</title>
      <link>https://yuan-feng1.github.io/project/hw3/</link>
      <pubDate>Mon, 14 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yuan-feng1.github.io/project/hw3/</guid>
      <description>&lt;p&gt;Malaria is caused by parasites from the genus Plasmodium, which could be spread to people by the bite of infected mosquitoes. In 2017, there were 219 million malaria cases that led to 435,000 deaths Malaria is an urgent public health priority for past decade. It has been estimated that around half of the world population are at risk today. Therefore, analysis on Malaria is useful in terms of global public health for research in preventive measures. I would like to share three visualizations using an online &lt;a href=&#34;https://github.com/rfordatascience/tidytuesday/tree/master/data/2018/2018-11-13&#34;&gt;dataset&lt;/a&gt;. These plots are generated by Python.
&lt;a href=&#34;https://github.com/yuan-feng1/bios-823-2019/blob/master/Homework_3_Yuan_Feng.ipynb&#34;&gt;Link to the Jupyter Notebook&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Plot 1  Avg. Malaria Deaths per 100,000 people (1990-2016)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Based on recent statistics, Africa carries a disproportionately high portion of the global malaria burden. As shown from the following heatmap measuring the number of death per 1000 people worldwide from 1990 to 2016. By the heavy concentration of red color on the map, it seems that most malaria cases and deaths occur in sub-Saharan Africa.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./sample1.jpg&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Plot 2 Number of Worldwide Malaria Deaths categorized by Age (1990-2016)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Most victims of Malaria are children. It is estimated to be one of the leading causes of child mortality. This could be demonstrated by the following plot. From 1990-2016, in terms of the total Malaria deaths, 77% of them are children under 5.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./sample2.jpg&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Plot 3 Number of Top 10 Countries with most Malaria Deaths (1990-2016)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Noy only sub-Saharan Africa has suffered most from Malaria, Nigeria and Congo are countries most affected by Malaria in the world. Nigeria alone accounts for 29.1% of total deaths caused by Malaria, and this number at Congo is 11.3%. The 10 most affected countries took up 76% of total Malaria deaths while the rest of world only accounts for 24.0% (1990-2016). Medical prevention of Malaria should be regarded as a top priority for these countries.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./sample3.jpg&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s all for this blog. Thanks for reading!&lt;/p&gt;
&lt;p&gt;Let me know if you have any comments/question. Feel free to find me at &lt;code&gt;yuan.feng347@duke.edu&lt;/code&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Project Euler Solutions</title>
      <link>https://yuan-feng1.github.io/project/hw2/</link>
      <pubDate>Sat, 29 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yuan-feng1.github.io/project/hw2/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Problem 13 Large sum - Solved by 224972&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this question, we are asked to:&lt;/p&gt;
&lt;p&gt;Work out the first ten digits of the sum of the following one-hundred 50-digit numbers. &lt;a href=&#34;https://projecteuler.net/problem=13&#34;&gt;link here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The thought process of this problem is quite straightforward: we first sum up the one-hundred 50-digit numbers, then with the result, turn it into a string, then slicing the first ten digits would solve the problem.&lt;/p&gt;
&lt;p&gt;In python, this is actually an easy process, using the built-in &lt;code&gt;sum()&lt;/code&gt; and &lt;code&gt;str()&lt;/code&gt; function, we could simply generate the sum, then turn it into a string and slice the first 10 digits.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;
def Solution_13&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;nums&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;:
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    The sum of nums array,
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    transform into string,
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    take the first 10 digits
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
    ttl &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sum&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;nums&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
    answer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; str&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;ttl&lt;span style=&#34;color:#f92672&#34;&gt;)[&lt;/span&gt;:10&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; answer

nums &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;
	37107287533902102798797998220837590246510135740250,
	46376937677490009712648124896970078050417018260538,
	74324986199524741059474233309513058123726617309629,
	91942213363574161572522430563301811072406154908250,
	23067588207539346171171980310421047513778063246676,
	89261670696623633820136378418383684178734361726757,
	28112879812849979408065481931592621691275889832738,
	44274228917432520321923589422876796487670272189318,
	47451445736001306439091167216856844588711603153276,
	70386486105843025439939619828917593665686757934951,
	62176457141856560629502157223196586755079324193331,
	64906352462741904929101432445813822663347944758178,
	92575867718337217661963751590579239728245598838407,
	58203565325359399008402633568948830189458628227828,
	80181199384826282014278194139940567587151170094390,
	35398664372827112653829987240784473053190104293586,
	86515506006295864861532075273371959191420517255829,
	71693888707715466499115593487603532921714970056938,
	54370070576826684624621495650076471787294438377604,
	53282654108756828443191190634694037855217779295145,
	36123272525000296071075082563815656710885258350721,
	45876576172410976447339110607218265236877223636045,
	17423706905851860660448207621209813287860733969412,
	81142660418086830619328460811191061556940512689692,
	51934325451728388641918047049293215058642563049483,
	62467221648435076201727918039944693004732956340691,
	15732444386908125794514089057706229429197107928209,
	55037687525678773091862540744969844508330393682126,
	18336384825330154686196124348767681297534375946515,
	80386287592878490201521685554828717201219257766954,
	78182833757993103614740356856449095527097864797581,
	16726320100436897842553539920931837441497806860984,
	48403098129077791799088218795327364475675590848030,
	87086987551392711854517078544161852424320693150332,
	59959406895756536782107074926966537676326235447210,
	69793950679652694742597709739166693763042633987085,
	41052684708299085211399427365734116182760315001271,
	65378607361501080857009149939512557028198746004375,
	35829035317434717326932123578154982629742552737307,
	94953759765105305946966067683156574377167401875275,
	88902802571733229619176668713819931811048770190271,
	25267680276078003013678680992525463401061632866526,
	36270218540497705585629946580636237993140746255962,
	24074486908231174977792365466257246923322810917141,
	91430288197103288597806669760892938638285025333403,
	34413065578016127815921815005561868836468420090470,
	23053081172816430487623791969842487255036638784583,
	11487696932154902810424020138335124462181441773470,
	63783299490636259666498587618221225225512486764533,
	67720186971698544312419572409913959008952310058822,
	95548255300263520781532296796249481641953868218774,
	76085327132285723110424803456124867697064507995236,
	37774242535411291684276865538926205024910326572967,
	23701913275725675285653248258265463092207058596522,
	29798860272258331913126375147341994889534765745501,
	18495701454879288984856827726077713721403798879715,
	38298203783031473527721580348144513491373226651381,
	34829543829199918180278916522431027392251122869539,
	40957953066405232632538044100059654939159879593635,
	29746152185502371307642255121183693803580388584903,
	41698116222072977186158236678424689157993532961922,
	62467957194401269043877107275048102390895523597457,
	23189706772547915061505504953922979530901129967519,
	86188088225875314529584099251203829009407770775672,
	11306739708304724483816533873502340845647058077308,
	82959174767140363198008187129011875491310547126581,
	97623331044818386269515456334926366572897563400500,
	42846280183517070527831839425882145521227251250327,
	55121603546981200581762165212827652751691296897789,
	32238195734329339946437501907836945765883352399886,
	75506164965184775180738168837861091527357929701337,
	62177842752192623401942399639168044983993173312731,
	32924185707147349566916674687634660915035914677504,
	99518671430235219628894890102423325116913619626622,
	73267460800591547471830798392868535206946944540724,
	76841822524674417161514036427982273348055556214818,
	97142617910342598647204516893989422179826088076852,
	87783646182799346313767754307809363333018982642090,
	10848802521674670883215120185883543223812876952786,
	71329612474782464538636993009049310363619763878039,
	62184073572399794223406235393808339651327408011116,
	66627891981488087797941876876144230030984490851411,
	60661826293682836764744779239180335110989069790714,
	85786944089552990653640447425576083659976645795096,
	66024396409905389607120198219976047599490197230297,
	64913982680032973156037120041377903785566085089252,
	16730939319872750275468906903707539413042652315011,
	94809377245048795150954100921645863754710598436791,
	78639167021187492431995700641917969777599028300699,
	15368713711936614952811305876380278410754449733078,
	40789923115535562561142322423255033685442488917353,
	44889911501440648020369068063960672322193204149535,
	41503128880339536053299340368006977710650566631954,
	81234880673210146739058568557934581403627822703280,
	82616570773948327592232845941706525094512325230608,
	22918802058777319719839450180888072429661980811197,
	77158542502016545090413245809786882778948721859617,
	72107838435069186155435662884062257473692284509516,
	20849603980134001723930671666823555245252804609722,
	53503534226472524250874054075591789781264330331690,
&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;

print&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Solution_13&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;nums&lt;span style=&#34;color:#f92672&#34;&gt;))&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After this code was run, the terminal would show the following results, and the final answer is 5537376230.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;
yuanfeng@yuans-MacBook-Air &lt;span style=&#34;color:#ae81ff&#34;&gt;823&lt;/span&gt; % python Euler_13.py
&lt;span style=&#34;color:#ae81ff&#34;&gt;5537376230&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Problem 31 Coin sums - Solved by 83654&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this question, we are asked:&lt;/p&gt;
&lt;p&gt;In the United Kingdom the currency is made up of pound (£) and pence (p). There are eight coins in general circulation:&lt;/p&gt;
&lt;p&gt;1p, 2p, 5p, 10p, 20p, 50p, £1 (100p), and £2 (200p).
It is possible to make £2 in the following way:&lt;/p&gt;
&lt;p&gt;1×£1 + 1×50p + 2×20p + 1×5p + 1×2p + 3×1p
How many different ways can £2 be made using any number of coins? &lt;a href=&#34;https://projecteuler.net/problem=31&#34;&gt;link here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is a typical problem of &lt;code&gt;Dynamic Programming&lt;/code&gt;. Based on the descriptions, the order of the coins does not matter, and there will be enough coins to make each combination. I followed the normal way of solving DP problems by going from a small base case, and dive deeper into more complex cases. &lt;code&gt;Tablation&lt;/code&gt; is an optimal choice to reduce the space complexity, I built a table with all the possible combinations given the total amount value.&lt;/p&gt;
&lt;p&gt;Here is a table of base case: only the 1 penny is used as indicated in the second column, and as the target increase, there is only one way to reach the targeted amount.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;target&lt;/th&gt;
&lt;th&gt;only 1 p&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0p&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1p&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2p&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3p&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4p&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We then move forward to using both 1 penny and 2 penny coins. The following table shows the ways of coin combinations to reach the targeted amount. Since 0 and 1 are number below 2, only 1 penny is used. As we move to higher value of targets, if the difference between two target values is the same as a given coin, then we have one more possible combination by simply adding one more coin.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;target&lt;/th&gt;
&lt;th&gt;1p, 2p&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0p&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1p&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2p&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3p&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4p&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;To generalize the previous process, we ran over all the possible coins. For each coin, we modify the table from values in the target column that equals the value of the coin until we reach the final target value. This is a quite straightforward algorithm that could be implemented by the following code in Python:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;
def Solution_31&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;target&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;:
  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  Dynamic programming to count the number
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  of coin combinations
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;#convert the amount to pennies&lt;/span&gt;
	sum &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; target*100
  &lt;span style=&#34;color:#75715e&#34;&gt;#total values in the target column&lt;/span&gt;
	ttl &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;1&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; + &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; * sum
  &lt;span style=&#34;color:#75715e&#34;&gt;#list of coins to choose from&lt;/span&gt;
 	coins &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;1, 2, 5, 10, 20, 50, 100, 200&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;#as we move towards to coins of larger value, update the table by adding new possible combinations&lt;/span&gt; 
	&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; coin in coins:
		&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i in range&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;sum + &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; - coin&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;:
			ttl&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;i + coin&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; +&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ttl&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;i&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
  &lt;span style=&#34;color:#75715e&#34;&gt;#return the result&lt;/span&gt;
	&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; str&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;ttl&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;-1&lt;span style=&#34;color:#f92672&#34;&gt;])&lt;/span&gt;

print&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Solution_31&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;2&lt;span style=&#34;color:#f92672&#34;&gt;))&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# result: 73682&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Problem 31 Coin sums - Solved by 23296&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this question, we are asked:&lt;/p&gt;
&lt;p&gt;Find the unique positive integer whose square has the form 1_2_3_4_5_6_7_8_9_0,
where each “_” is a single digit.&lt;/p&gt;
&lt;p&gt;Filling in the blank spaces with 0 or 9 will give us the minimum or maximum value of the square. We take the square root and the range of answer is [1010101010, 1389026623].&lt;/p&gt;
&lt;p&gt;The last digit in the required form is 0, therefore the number we hope to find should also end in 0, this in turn would mean its square will end in two 0s. This will further reduce the range of answers to [101010101, 138902662]. Now we could look at the second-last number. Since its square ends in 900, the target number should end in either 70 or 30.&lt;/p&gt;
&lt;p&gt;Now we have reduced the search range to a much smaller scale. We first generate the minimum and maximum values, then write a for loop to go through each number in this range. If the last two numbers are 70 or 30, we then check if its square fits in 1_2_3_4_5_6_7_8_9_0.&lt;/p&gt;
&lt;p&gt;Here is an implementation of the previous algorithm.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;
import math

def helper&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;n&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;:
  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  determines if the given number fits in 1_2_3_4_5_6_7_8_9_0
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i in range&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;8,0,-1&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;:
      n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;n / 100&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; n % &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; !&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; i:
          &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; False;
  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; True;

def Solution_206&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt;:  
  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  generate the range of answers and check each value
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;  
  min_val &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;math.sqrt&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;10203040506070809&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; / 10&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;;
  max_val &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; int&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;math.sqrt&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;19293949596979899&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; / 10&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; + 1;
    
  &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i in range&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;min_val, max_val&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;:
  &lt;span style=&#34;color:#75715e&#34;&gt;#if the value ends in 3 or 7, we check its square&lt;/span&gt;
      num &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; i * &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; + 3;
      &lt;span style=&#34;color:#75715e&#34;&gt;#if accepted, break the loop and print the value&lt;/span&gt;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; helper&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;num*num&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;:
          break;
        
      num &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; i * &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; + 7;
      &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; helper&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;num* num&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;:
          break;
  print&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;num * 10&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;;

&lt;span style=&#34;color:#75715e&#34;&gt;#result: 1389019170&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Congratulations! Now you have figured out three interesting questions from Project Euler. If you find this article interesting, feel free to check out &lt;a href=&#34;https://projecteuler.net/&#34;&gt;Project Euler&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/13oqgkZA9Pqa4BGbakiPZVguvAkShETve?usp=sharing&#34;&gt;Screenshots of Solved problems&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How I built my own protfolio website</title>
      <link>https://yuan-feng1.github.io/project/hw1/</link>
      <pubDate>Sat, 22 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yuan-feng1.github.io/project/hw1/</guid>
      <description>&lt;p&gt;A portfolio website is a great choice for you to showcase your work and let recruiters know more about you. With Github Page, we could easily set up a personal website for free. And using Hugo, you can have access to hundreds of special themes to choose from.&lt;/p&gt;
&lt;p&gt;For me, I&amp;rsquo;m using Mac OS system and plan to build up this website from command line. Below is a detailed tutorial of how I successfully set up my website from scratch - Stay Tuned!&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/yuan-feng1/yuan-feng1.github.io&#34;&gt;Link to my Github repository&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Install Hugo and Git&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First open the terminal, and input the following command-line. Note that if you do not have &lt;code&gt;homebrew&lt;/code&gt; installed, you may need to install it first.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;brew install hugo
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;I recommend installing Git as well. run &lt;code&gt;git --version&lt;/code&gt; in your command-line for checking.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Build on local machine&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Make sure to sit inside the directory to save the website. And run the following to initialize a new site:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cd /Users/yuanfeng/Desktop
hugo new site site_name
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then, we should have a new folder with the name we just made. It will come with a list of folders, and we will dig deeper into those folders in a minute.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Select a theme&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I personally enjoy designs of minimalist and the use of white or black as its main colors. It only takes googling to find ready-to-go themes but it took me a while to find my favorite.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Then I run the following command line in the terminal to download the contents in themes folder:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd site_name
cd themes
git clone https://github.com/themefisher/academia-hugo
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And it&amp;rsquo;s also necessary to make sure the configurations are correct. Here I made some changes in the config.toml.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;baseurl &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;https://[your github username].github.io/&amp;#34;&lt;/span&gt;
languageCode &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;en-us&amp;#34;&lt;/span&gt;
title &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;the website title shown on the tab&amp;#34;&lt;/span&gt;
theme &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;the same as theme name (exactly the folder name) in your themes folder&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Test locally&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I wanted to see how the webpage currently looks like by running the following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cd site_name
hugo server
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The following indicated success in running it locally. By going to &lt;code&gt;http://localhost:1313/ &lt;/code&gt;in my web browser, I could see my work so far and observe changes real-time.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;Built in &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; ms
Watching &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; changes in /Users/yuanfeng/site/yuan/&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;archetypes,content,data,layouts,static&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
Watching &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; config changes in /Users/yuanfeng/site/yuan/config.toml
Environment: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;development&amp;#34;&lt;/span&gt;
Serving pages from memory
Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender
Web Server is available at http://localhost:1313/ &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;bind address 127.0.0.1&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
Press Ctrl+C to stop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Personalize my website&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The template comes with a variety of different sections such as Publications, Recent Posts and Contact. However, in order for the main page to stay concise and minimal, I removed the less appealing and related components and replaced the sample photos and texts with mine by editing html and md files.&lt;/p&gt;
&lt;p&gt;Another main change compared with the original template is the header and dropdown. This turned out to be tricky as I needed to tweak the Javascript code as well. The final results seem great!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./sample.jpg&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Deploy to Git Pages&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Last step is to render my website to Github Pages. I started by running the following commnad, which will generate a folder called &lt;code&gt;public&lt;/code&gt; and it will contain the required web files.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cd site_name
hugo
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create Github Repository&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I wanted to publish my site as my github name. In order to do that, I created a new branch named &lt;code&gt;&amp;lt;USERNAME&amp;gt;.github.io.&lt;/code&gt; and set it to public.&lt;/p&gt;
&lt;p&gt;Then the following command could sync the website to my github.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cd public
git init
git add .
git remote add origin https://github.com/username/username.github.io.git
git commit -m “first commit”
git push origin master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After completing the committing, I went to my repository and clicked on settings, then scrolled to the section of Github Pages. It successfully returned the link of my personal website:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;https://yuan-feng1.github.io/&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;And my personal website was successfully published.&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s all for this blog. Thanks for reading!&lt;/p&gt;
&lt;p&gt;Let me know if you have any comments/question. Feel free to find me at &lt;code&gt;yuan.feng347@duke.edu&lt;/code&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Predict Patient Discharge Location with MIMIC Dataset</title>
      <link>https://yuan-feng1.github.io/project/final/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yuan-feng1.github.io/project/final/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;./0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;project-overview&#34;&gt;Project Overview&lt;/h2&gt;
&lt;p&gt;The utilization of hospital resources is an urgent topic worldwide. Often we could hear in the news, especially in times of the global pandemic, of the space shortage in hospitals for patients in need. The main goal of this project is to construct a classification system built with state-of-art machine learning models to predict the discharge location of patients with ICU admission based on a series of records, such as demographics, vital signs, laboratory tests, medications information, and so on.&lt;/p&gt;
&lt;p&gt;The major focus of our prediction will be on SNF which stands for skilled nursing facilities and other hospitals, Since the number of patients assigned to these facilities best represents the allocation of medical resources and hospital capacity.&lt;/p&gt;
&lt;h2 id=&#34;my-responsibility&#34;&gt;My Responsibility&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Initial operations on accessing the data &amp;amp; Data imputation on missing values.&lt;/li&gt;
&lt;li&gt;Implemented Random Forest modeling with a series of hyperparameter tuning for optimal performance.&lt;/li&gt;
&lt;li&gt;Designed workflow and layout of interactive ML real-time prediction using Flask app.&lt;/li&gt;
&lt;li&gt;Finished the real-time prediction engine using machine learning models.&lt;/li&gt;
&lt;li&gt;Data product &amp;amp; Github aggregation and calibration; Gthub readme organizations &amp;amp; updates (cooperated with all team members).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;audience&#34;&gt;Audience&lt;/h2&gt;
&lt;p&gt;Our platform aims to serve the hospital administration team, the inquisitive researchers and curious patients. The multi-page dashboard serves as a tool to monitor occupancy and clinical results of patients, and provide comprehensive demonstration. The online ML prediction model provides real-time results of clinical outcome, which will aid in decision-making process of patients and doctors.&lt;/p&gt;
&lt;h2 id=&#34;goals&#34;&gt;Goals&lt;/h2&gt;
&lt;p&gt;Our project will be able to demonstrate the hospital bed occupancy and the usage of hospital resources so that the doctors are able to make better decisions. Moreover, it will display vivid visualizations of the overall trend of the patients in hospital. And our platform will help not only the doctors by the patients and inquisitive people by offering an online machine learning platform.&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://mimic.physionet.org/&#34;&gt;MIMIC data&lt;/a&gt; is a public-available database which is comprised of ~60,000 deidentified large-scale health-related data.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data Preprocessing&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Data pre-processing was conducted using multiple packages in Python, including pandas and numpy. Subsequent tasks include looking at the distribution of each varaible, converting to appropriate datatype，then checking for the missingness of the data and conducted imputation and testing performance on dummy model.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Technical Stack I mastered&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Data processing: pandas, numpy / Visualization: pyplot, seaborn&lt;/p&gt;
&lt;p&gt;Machine Learning Implementation: scikit-learn, optuna, xgboost&lt;/p&gt;
&lt;p&gt;Deployment: dash, Flask&lt;/p&gt;
&lt;p&gt;Git version control: branch set-up, push, commit, merge, pull, resolve issues&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;dashboard-eda&#34;&gt;Dashboard EDA&lt;/h2&gt;
&lt;p&gt;First, we looked at the distribution of the MIMIC dataset. The majority of patients were discharged to their own home(58.7%), and the second-biggest location is SNF(19.9%), and the rest were sent to other facility or dead. The number of records placed on the right is a number-based illustration of this distribution.
&lt;img src=&#34;./1.png&#34; alt=&#34;png&#34;&gt;
Secondly, this stacked bar chart demonstrated the admission type of patients. The majority of admitted patients were in the emergency category, newborn and elective comes second and urgent cases are the least. This indicates the classification results in the dataset was not balanced, which we will address in the modeling process for better performance.
&lt;img src=&#34;./2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;We also plotted the confusin matrix to show the correlation of this dataset. Overall, there was not much collinearity issue in this dataset.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;model-analysis&#34;&gt;Model Analysis&lt;/h2&gt;
&lt;p&gt;We utilized multiple machine learning algorithms to approach this classfication problem. Based on our research, the currently most popular methods include Random Forest, Xgboost, SVM and Naive Bayes. After conducting data preprocessing and dummy model as a baseline comparison, we developed the each of the models with hyper-parameter tuning for model training, and based on a series of metrics such as accuracy, precision, recall and F1, selected the optimal model for future analysis.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;random_grid &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;n_estimators&amp;#39;&lt;/span&gt;: n_estimators,
               &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;max_features&amp;#39;&lt;/span&gt;: max_features,
               &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;max_depth&amp;#39;&lt;/span&gt;: max_depth,
               &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;min_samples_split&amp;#39;&lt;/span&gt;: min_samples_split,
               &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;min_samples_leaf&amp;#39;&lt;/span&gt;: min_samples_leaf,
               &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bootstrap&amp;#39;&lt;/span&gt;: bootstrap&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# Use the random grid to search for best hyperparameters&lt;/span&gt;
rf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RandomForestClassifier&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# Random search of parameters, using 3 fold cross validation, search across 100 different combinations, and use all available cores&lt;/span&gt;
rf_random &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RandomizedSearchCV&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;estimator &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rf, param_distributions &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random_grid, n_iter &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; 100, cv &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; 3, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;2, random_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;42, n_jobs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; -1&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# Fit the random search model&lt;/span&gt;
rf_random.fit&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;X_train, y_train&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;           
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;random-forest-modeling&#34;&gt;Random Forest Modeling&lt;/h2&gt;
&lt;p&gt;With regards to model development process, I built the Random Forest model, which is an ensemble learning method. It is trained on different parts of the data, and builds multiple decision trees during the training process then return the prediction by finding the most votes from individual trees. The major advantages of Random Forests is that it helps with our goal of  boosting model performance and solving overfitting issues, but these advantages may come at the expense of some loss of interpretability.&lt;/p&gt;
&lt;p&gt;For thr hyperparameter tuning process, I initially generated a grid of possible parameters including &amp;ldquo;n_estimators&amp;rdquo;, &amp;ldquo;min_samples_split&amp;rdquo;, &amp;ldquo;min_samples_leaf&amp;rdquo;, &amp;ldquo;max_features&amp;rdquo;, &amp;ldquo;max_depth&amp;rdquo;,  and &amp;ldquo;bootstrap&amp;rdquo; for the model to choose from.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#parameters of the best model&lt;/span&gt;
rf_random.best_params_

&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;n_estimators&amp;#39;&lt;/span&gt;: 1100,
 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;min_samples_split&amp;#39;&lt;/span&gt;: 10,
 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;min_samples_leaf&amp;#39;&lt;/span&gt;: 2,
 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;max_features&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sqrt&amp;#39;&lt;/span&gt;,
 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;max_depth&amp;#39;&lt;/span&gt;: 50,
 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bootstrap&amp;#39;&lt;/span&gt;: False&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With the help of RandomizedSearchCV function, performed gird search to find the set of parameters that returns highest accuracy values. After completing the tuning process, the best parameters are shown above.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./rf.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Random has proved to be a very powerful model for classfication problems. The accuracy has boosted to 0.99 on train data and reached 0.68 on test data. The metrics were also satisfying for precision, recall and F1, indicating it performed well on four categories as well.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Table 1 - Model evaluations on train dataset&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Train&lt;/th&gt;
&lt;th&gt;Dummy Classifier&lt;/th&gt;
&lt;th&gt;Logistic Regression&lt;/th&gt;
&lt;th&gt;SVM&lt;/th&gt;
&lt;th&gt;KNN&lt;/th&gt;
&lt;th&gt;Random Forest&lt;/th&gt;
&lt;th&gt;Xgboost&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Accuracy&lt;/td&gt;
&lt;td&gt;0.59&lt;/td&gt;
&lt;td&gt;0.65&lt;/td&gt;
&lt;td&gt;0.70&lt;/td&gt;
&lt;td&gt;0.64&lt;/td&gt;
&lt;td&gt;0.99&lt;/td&gt;
&lt;td&gt;0.77&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Precision&lt;/td&gt;
&lt;td&gt;0.34&lt;/td&gt;
&lt;td&gt;0.64&lt;/td&gt;
&lt;td&gt;0.68&lt;/td&gt;
&lt;td&gt;0.59&lt;/td&gt;
&lt;td&gt;0.99&lt;/td&gt;
&lt;td&gt;0.76&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Recall&lt;/td&gt;
&lt;td&gt;0.59&lt;/td&gt;
&lt;td&gt;0.65&lt;/td&gt;
&lt;td&gt;0.70&lt;/td&gt;
&lt;td&gt;0.64&lt;/td&gt;
&lt;td&gt;0.99&lt;/td&gt;
&lt;td&gt;0.77&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;F1&lt;/td&gt;
&lt;td&gt;0.43&lt;/td&gt;
&lt;td&gt;0.60&lt;/td&gt;
&lt;td&gt;0.66&lt;/td&gt;
&lt;td&gt;0.59&lt;/td&gt;
&lt;td&gt;0.99&lt;/td&gt;
&lt;td&gt;0.75&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The above table shows all of modeling results. All models performed quite well after cross-validation and tuning process, with an accuracy above 64% for all models except dummy model. Random Forest ranks top in terms of performance on train data. It has almost perfect results in terms of classification.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Table 2 - Model evaluations on test dataset&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Test&lt;/th&gt;
&lt;th&gt;Dummy Classifier&lt;/th&gt;
&lt;th&gt;Logistic Regression&lt;/th&gt;
&lt;th&gt;SVM&lt;/th&gt;
&lt;th&gt;KNN&lt;/th&gt;
&lt;th&gt;Random Forest&lt;/th&gt;
&lt;th&gt;Xgboost&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Accuracy&lt;/td&gt;
&lt;td&gt;0.59&lt;/td&gt;
&lt;td&gt;0.65&lt;/td&gt;
&lt;td&gt;0.60&lt;/td&gt;
&lt;td&gt;0.66&lt;/td&gt;
&lt;td&gt;0.68&lt;/td&gt;
&lt;td&gt;0.68&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Precision&lt;/td&gt;
&lt;td&gt;0.34&lt;/td&gt;
&lt;td&gt;0.60&lt;/td&gt;
&lt;td&gt;0.63&lt;/td&gt;
&lt;td&gt;0.55&lt;/td&gt;
&lt;td&gt;0.65&lt;/td&gt;
&lt;td&gt;0.65&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Recall&lt;/td&gt;
&lt;td&gt;0.59&lt;/td&gt;
&lt;td&gt;0.65&lt;/td&gt;
&lt;td&gt;0.66&lt;/td&gt;
&lt;td&gt;0.60&lt;/td&gt;
&lt;td&gt;0.68&lt;/td&gt;
&lt;td&gt;0.68&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;F1&lt;/td&gt;
&lt;td&gt;0.43&lt;/td&gt;
&lt;td&gt;0.59&lt;/td&gt;
&lt;td&gt;0.62&lt;/td&gt;
&lt;td&gt;0.53&lt;/td&gt;
&lt;td&gt;0.64&lt;/td&gt;
&lt;td&gt;0.66&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;However, when we look at results on test data, random forest model performed roughly the same as Xgboost modeling. The accuracy of Random Forest is 0.68, which is much lower than on train data, which indictas potential issues of overfitting. Based on a combination of performance and consistency, we chose Xgboost which has the highest accuracy of 68% with a overall satisfactory performance on all four categories. All F1, recall and precision values are aligned.&lt;/p&gt;
&lt;h2 id=&#34;reason-why-xgboost-outperformed&#34;&gt;Reason why Xgboost outperformed&lt;/h2&gt;
&lt;p&gt;Our results are aligned in practice of various data science competitions and it also makes sense because for a theoretical standpoint.
Xgboost is essentially a very powerful model especially for classification problems. XGBoost stands for extreme gradient boosting. Boosting is an ensemble technique which trains models in sequence rather than training models separately. Each new model will correct the errors made by the previous ones and are added sequentially until no further improvements are available.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;online-ml-real-time-prediction&#34;&gt;Online ML Real-Time Prediction&lt;/h2&gt;
&lt;p&gt;Online real-time prediction is one of the unique features of our data product. I implemented this platform, from designing the initial layout, seraching for best tools to implementation. The backend I decided to use is Flask, because it is lightweight with simple syntax comparing with other backend options, and it is based on Python which has higher popularity in DS field. Moreover, Flask app could be combined with Dash to create fascinating visualization effects, and it integrates perfectly with the dashboard.&lt;/p&gt;
&lt;p&gt;Total of 10 variables are available for users to manually input with descriptions by the side. Five authors features are the top five are featuring protest plot while the rest are features with higher availability to the general public. There are over 80 features in our data and they will be unrealistic for user input every variable. Below is the input section:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./10.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;This was a great opportunity for me to brush-up on web dev skills. I used HTML and CSS for writing the structure and decoration of this interface, and callbacks in Javascript to render the inputs. Here shows a part of code to demonstarte this process.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;server &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; flask.Flask&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;__name__&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
app &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dash.Dash&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;__name__, server&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;server,external_stylesheets&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;external_stylesheets&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;

layout &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; html.Div&lt;span style=&#34;color:#f92672&#34;&gt;([&lt;/span&gt;
    dbc.Container&lt;span style=&#34;color:#f92672&#34;&gt;([&lt;/span&gt;
        dbc.Row&lt;span style=&#34;color:#f92672&#34;&gt;([&lt;/span&gt; dbc.Col&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;html.H1&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Real Time Prediction Serverless App&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;, className&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;mb-2&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;])&lt;/span&gt;,
    dbc.Container&lt;span style=&#34;color:#f92672&#34;&gt;([&lt;/span&gt;
        dbc.Row&lt;span style=&#34;color:#f92672&#34;&gt;([&lt;/span&gt;dbc.Col&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;dbc.Card&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;html.H3&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;children&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Input Features&amp;#39;&lt;/span&gt;,className&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;text-center text-light bg-dark&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;, body&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;dark&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;, className&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;mt-4 mb-4&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)])&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;])&lt;/span&gt;,
    dbc.FormGroup&lt;span style=&#34;color:#f92672&#34;&gt;([&lt;/span&gt;dbc.Label&lt;span style=&#34;color:#f92672&#34;&gt;([&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Binary Input: if insurance type is &amp;#39;medicare&amp;#39; then 1 else 0&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;])&lt;/span&gt;,
        dbc.Input&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;id&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;INSURANCE_Medicare&amp;#34;&lt;/span&gt;,type&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;number&amp;#34;&lt;/span&gt;, placeholder&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Enter or select...&amp;#34;&lt;/span&gt;,min&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;0, max&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;1&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;])&lt;/span&gt;,
 
@app.callback&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;
    Output&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;out&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;children&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;,
    &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;Input&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;show&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;n_clicks&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)]&lt;/span&gt;,
    
    state&lt;span style=&#34;color:#f92672&#34;&gt;=[&lt;/span&gt;State&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Age&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;value&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;,
           State&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Gender&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;value&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;,
           State&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;HeartRate_Mean&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;value&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;,
           State&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Glucose_Mean&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;value&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;,
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Therefore, besides these 10 selected features, I used mode or mean of the rest remaining variables available to public such as age, sex, and heart rate level, etc.There are over 80 features in our data and it will be unrealistic for user to input every variable. Therefore besides these 10 selected features, we use mod or mean of the rest remaining variables.&lt;/p&gt;
&lt;p&gt;There are over 80 features in our data and they will be unrealistic for user input every variable. Therefore besides these 10 selected features, we use mode or meaning of the remaining variables.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./6.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once the user finished all the required input. Upon clicking the go button our cloud-based model will display the most accurate prediction based on the input. Here we can see that the best gas according to my input is home which means the patient with such features is most likely to be discharged to home.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;my-takeaways-from-this-project&#34;&gt;My takeaways from this project&lt;/h2&gt;
&lt;p&gt;I&amp;rsquo;m really glad to have this great opportunity to work with MIMIC EHR dataset, I have always been intrigued by application of Data Science in biomedical filed and this final project marked a milestone on my trajectory into personal &amp;ldquo;wild west&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;This was a good combination of skills learned in class and real-world challenges, and I feel very satisfied to successfully implement a complete inteface based on ML modeling and analysis. Big shout-out to my teammates for a semester&amp;rsquo;s hard work.😊 Thanks to Prof. Chan and TA for all the precious instructions &amp;amp; suggestions.🎉&lt;/p&gt;
&lt;p&gt;I hope you&amp;rsquo;re enjoying this blog article and find our data product interesting. Here is the &lt;a href=&#34;https://bios823-mimic-dashboard.ue.r.appspot.com/deploy_app&#34;&gt;Interactive App&lt;/a&gt;. &lt;a href=&#34;https://github.com/biostats823-final-project/MIMIC-Predictive-Modeling&#34;&gt;GitHub Link of models&lt;/a&gt; is here. &lt;a href=&#34;https://github.com/biostats823-final-project/MIMIC-Dashboard&#34;&gt;GitHub Link of dashboard&lt;/a&gt; can be found here.&lt;/p&gt;
&lt;p&gt;Thanks for reading！&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;Plotly website &lt;a href=&#34;https://plotly.com/&#34;&gt;https://plotly.com/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
