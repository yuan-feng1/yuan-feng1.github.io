<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ML on Yuan Feng</title>
    <link>https://yuan-feng1.github.io/tags/ml/</link>
    <description>Recent content in ML on Yuan Feng</description>
    <generator>Source Themes academia (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 16 Mar 2021 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://yuan-feng1.github.io/tags/ml/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Detecting Solar Panels From Satellite Imagery</title>
      <link>https://yuan-feng1.github.io/project/solar/</link>
      <pubDate>Tue, 16 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://yuan-feng1.github.io/project/solar/</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;Due to the rising concern over the pollution from the current energy sources, solar power has been regarded as one of the most promising methods to provide energy at low pollution and low environmental footprint. As of the end of 2018, solar power accounted for around 1.6% of the total power consumed in the United States amounting to 64.2 GW. Furthermore, solar power has ranked consistently as the first or second fastest growing power source in the US since 2013. Moreover, unlike nuclear, wind or hydrothermal energy solar energy can be easily harnessed from rooftops using photovoltaic cells. Solar power using photovoltaic solar panels is a quickly growing source of power across US households with increasing rates of adoption. Tracking the installation of solar panels across the nation to study the rates of adoption is often cumbersome and inaccurate - for such methods often involve self-reporting, monitoring sales of solar panels etc. A much more recent technique to track the harnessing of solar panels across the nation involves using machine learning models on satellite imagery. These models use a variety of techniques, both simple and intricate, to accurately identify the existence of solar panels in satellite images with high accuracy.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./d1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;goals-and-reports&#34;&gt;Goals and Reports&lt;/h2&gt;
&lt;p&gt;In order to obtain a thorough understanding of the current state of individual solar panel installation and usage both on a local and national scale, an automated method of identification is required for classifying the existence of solar panels based on pre-processed satellite images. In the notion of machine learning algorithms, the original model is built on the basis of an educated estimation and exploration of the dataset and trained multiple times on the training data with possible future stages of parameter tuning. The model performance will be evaluated based on its test data, which in this case are images unseen by the model beforehand. The finalized model will be able to provide classification on newly imported images in a scalable fashion. With the implementation of machine learning to solar panel image classification, the cost and time required to identify installed solar panels could be potentially reduced and will help the industry better provide renewable, clean and affordable alternative energy sources.&lt;/p&gt;
&lt;p&gt;In this project, we discuss four different approaches to identify and classify solar panels in satellite images. We lay specific emphasis on two different feature extraction methods namely Histogram and Gradients (HOG) and Color Filter Feature Extraction (CFFE). We then use a K-Nearest Neighbour (KNN) Classifier in both cases to classify the images. These methods achieved an area under the curve (AUC) of 0.800 and 0.837 respectively. In our third approach, we develop an ensemble model combining both the earlier described feature extraction methods. The AUC in this case was 0.888. Finally we developed a Convolutional Neural Network (CNN) with an AUC of 0.983. We compare the different approaches and analyze where they performed well and where they can be improved.&lt;/p&gt;
&lt;p&gt;The project code can be found &lt;a href=&#34;https://github.com/yuanfeng2/solar_panel_detection_CNN&#34;&gt;here&lt;/a&gt;, and a pdf of the report is located &lt;a href=&#34;https://github.com/yuanfeng2/solar_panel_detection_CNN/blob/master/Solar%20Panel%20Detection.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Patient Discharge Location Predicion with MIMIC Dataset</title>
      <link>https://yuan-feng1.github.io/project/hospital/</link>
      <pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://yuan-feng1.github.io/project/hospital/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;./0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;project-overview&#34;&gt;Project Overview&lt;/h2&gt;
&lt;p&gt;The utilization of hospital resources is an urgent topic worldwide. Often we could hear in the news, especially in times of the global pandemic, of the space shortage in hospitals for patients in need. The main goal of this project is to construct a classification system built with state-of-art machine learning models to predict the discharge location of patients with ICU admission based on a series of records, such as demographics, vital signs, laboratory tests, medications information, and so on.&lt;/p&gt;
&lt;p&gt;The major focus of our prediction will be on SNF which stands for skilled nursing facilities and other hospitals, Since the number of patients assigned to these facilities best represents the allocation of medical resources and hospital capacity.&lt;/p&gt;
&lt;h2 id=&#34;my-responsibility&#34;&gt;My Responsibility&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Initial operations on accessing the data &amp;amp; Data imputation on missing values.&lt;/li&gt;
&lt;li&gt;Implemented Random Forest modeling with a series of hyperparameter tuning for optimal performance.&lt;/li&gt;
&lt;li&gt;Designed workflow and layout of interactive ML real-time prediction using Flask app.&lt;/li&gt;
&lt;li&gt;Finished the real-time prediction engine using machine learning models.&lt;/li&gt;
&lt;li&gt;Data product &amp;amp; Github aggregation and calibration; Gthub readme organizations &amp;amp; updates (cooperated with all team members).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;audience&#34;&gt;Audience&lt;/h2&gt;
&lt;p&gt;Our platform aims to serve the hospital administration team, the inquisitive researchers and curious patients. The multi-page dashboard serves as a tool to monitor occupancy and clinical results of patients, and provide comprehensive demonstration. The online ML prediction model provides real-time results of clinical outcome, which will aid in decision-making process of patients and doctors.&lt;/p&gt;
&lt;h2 id=&#34;goals&#34;&gt;Goals&lt;/h2&gt;
&lt;p&gt;Our project will be able to demonstrate the hospital bed occupancy and the usage of hospital resources so that the doctors are able to make better decisions. Moreover, it will display vivid visualizations of the overall trend of the patients in hospital. And our platform will help not only the doctors by the patients and inquisitive people by offering an online machine learning platform.&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://mimic.physionet.org/&#34;&gt;MIMIC data&lt;/a&gt; is a public-available database which is comprised of ~60,000 deidentified large-scale health-related data.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data Preprocessing&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Data pre-processing was conducted using multiple packages in Python, including pandas and numpy. Subsequent tasks include looking at the distribution of each varaible, converting to appropriate datatypeÔºåthen checking for the missingness of the data and conducted imputation and testing performance on dummy model.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Technical Stack I mastered&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Data processing: pandas, numpy / Visualization: pyplot, seaborn&lt;/p&gt;
&lt;p&gt;Machine Learning Implementation: scikit-learn, optuna, xgboost&lt;/p&gt;
&lt;p&gt;Deployment: dash, Flask&lt;/p&gt;
&lt;p&gt;Git version control: branch set-up, push, commit, merge, pull, resolve issues&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;dashboard-eda&#34;&gt;Dashboard EDA&lt;/h2&gt;
&lt;p&gt;First, we looked at the distribution of the MIMIC dataset. The majority of patients were discharged to their own home(58.7%), and the second-biggest location is SNF(19.9%), and the rest were sent to other facility or dead. The number of records placed on the right is a number-based illustration of this distribution.
&lt;img src=&#34;./1.png&#34; alt=&#34;png&#34;&gt;
Secondly, this stacked bar chart demonstrated the admission type of patients. The majority of admitted patients were in the emergency category, newborn and elective comes second and urgent cases are the least. This indicates the classification results in the dataset was not balanced, which we will address in the modeling process for better performance.
&lt;img src=&#34;./2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;We also plotted the confusin matrix to show the correlation of this dataset. Overall, there was not much collinearity issue in this dataset.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;model-analysis&#34;&gt;Model Analysis&lt;/h2&gt;
&lt;p&gt;We utilized multiple machine learning algorithms to approach this classfication problem. Based on our research, the currently most popular methods include Random Forest, Xgboost, SVM and Naive Bayes. After conducting data preprocessing and dummy model as a baseline comparison, we developed the each of the models with hyper-parameter tuning for model training, and based on a series of metrics such as accuracy, precision, recall and F1, selected the optimal model for future analysis.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;random_grid &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;n_estimators&amp;#39;&lt;/span&gt;: n_estimators,
               &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;max_features&amp;#39;&lt;/span&gt;: max_features,
               &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;max_depth&amp;#39;&lt;/span&gt;: max_depth,
               &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;min_samples_split&amp;#39;&lt;/span&gt;: min_samples_split,
               &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;min_samples_leaf&amp;#39;&lt;/span&gt;: min_samples_leaf,
               &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bootstrap&amp;#39;&lt;/span&gt;: bootstrap&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# Use the random grid to search for best hyperparameters&lt;/span&gt;
rf &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RandomForestClassifier&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# Random search of parameters, using 3 fold cross validation, search across 100 different combinations, and use all available cores&lt;/span&gt;
rf_random &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RandomizedSearchCV&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;estimator &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rf, param_distributions &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; random_grid, n_iter &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; 100, cv &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; 3, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;2, random_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;42, n_jobs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; -1&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# Fit the random search model&lt;/span&gt;
rf_random.fit&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;X_train, y_train&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;           
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;random-forest-modeling&#34;&gt;Random Forest Modeling&lt;/h2&gt;
&lt;p&gt;With regards to model development process, I built the Random Forest model, which is an ensemble learning method. It is trained on different parts of the data, and builds multiple decision trees during the training process then return the prediction by finding the most votes from individual trees. The major advantages of Random Forests is that it helps with our goal of  boosting model performance and solving overfitting issues, but these advantages may come at the expense of some loss of interpretability.&lt;/p&gt;
&lt;p&gt;For thr hyperparameter tuning process, I initially generated a grid of possible parameters including &amp;ldquo;n_estimators&amp;rdquo;, &amp;ldquo;min_samples_split&amp;rdquo;, &amp;ldquo;min_samples_leaf&amp;rdquo;, &amp;ldquo;max_features&amp;rdquo;, &amp;ldquo;max_depth&amp;rdquo;,  and &amp;ldquo;bootstrap&amp;rdquo; for the model to choose from.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#parameters of the best model&lt;/span&gt;
rf_random.best_params_

&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;n_estimators&amp;#39;&lt;/span&gt;: 1100,
 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;min_samples_split&amp;#39;&lt;/span&gt;: 10,
 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;min_samples_leaf&amp;#39;&lt;/span&gt;: 2,
 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;max_features&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sqrt&amp;#39;&lt;/span&gt;,
 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;max_depth&amp;#39;&lt;/span&gt;: 50,
 &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bootstrap&amp;#39;&lt;/span&gt;: False&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With the help of RandomizedSearchCV function, performed gird search to find the set of parameters that returns highest accuracy values. After completing the tuning process, the best parameters are shown above.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./rf.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Random has proved to be a very powerful model for classfication problems. The accuracy has boosted to 0.99 on train data and reached 0.68 on test data. The metrics were also satisfying for precision, recall and F1, indicating it performed well on four categories as well.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Table 1 - Model evaluations on train dataset&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Train&lt;/th&gt;
&lt;th&gt;Dummy Classifier&lt;/th&gt;
&lt;th&gt;Logistic Regression&lt;/th&gt;
&lt;th&gt;SVM&lt;/th&gt;
&lt;th&gt;KNN&lt;/th&gt;
&lt;th&gt;Random Forest&lt;/th&gt;
&lt;th&gt;Xgboost&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Accuracy&lt;/td&gt;
&lt;td&gt;0.59&lt;/td&gt;
&lt;td&gt;0.65&lt;/td&gt;
&lt;td&gt;0.70&lt;/td&gt;
&lt;td&gt;0.64&lt;/td&gt;
&lt;td&gt;0.99&lt;/td&gt;
&lt;td&gt;0.77&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Precision&lt;/td&gt;
&lt;td&gt;0.34&lt;/td&gt;
&lt;td&gt;0.64&lt;/td&gt;
&lt;td&gt;0.68&lt;/td&gt;
&lt;td&gt;0.59&lt;/td&gt;
&lt;td&gt;0.99&lt;/td&gt;
&lt;td&gt;0.76&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Recall&lt;/td&gt;
&lt;td&gt;0.59&lt;/td&gt;
&lt;td&gt;0.65&lt;/td&gt;
&lt;td&gt;0.70&lt;/td&gt;
&lt;td&gt;0.64&lt;/td&gt;
&lt;td&gt;0.99&lt;/td&gt;
&lt;td&gt;0.77&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;F1&lt;/td&gt;
&lt;td&gt;0.43&lt;/td&gt;
&lt;td&gt;0.60&lt;/td&gt;
&lt;td&gt;0.66&lt;/td&gt;
&lt;td&gt;0.59&lt;/td&gt;
&lt;td&gt;0.99&lt;/td&gt;
&lt;td&gt;0.75&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The above table shows all of modeling results. All models performed quite well after cross-validation and tuning process, with an accuracy above 64% for all models except dummy model. Random Forest ranks top in terms of performance on train data. It has almost perfect results in terms of classification.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Table 2 - Model evaluations on test dataset&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Test&lt;/th&gt;
&lt;th&gt;Dummy Classifier&lt;/th&gt;
&lt;th&gt;Logistic Regression&lt;/th&gt;
&lt;th&gt;SVM&lt;/th&gt;
&lt;th&gt;KNN&lt;/th&gt;
&lt;th&gt;Random Forest&lt;/th&gt;
&lt;th&gt;Xgboost&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Accuracy&lt;/td&gt;
&lt;td&gt;0.59&lt;/td&gt;
&lt;td&gt;0.65&lt;/td&gt;
&lt;td&gt;0.60&lt;/td&gt;
&lt;td&gt;0.66&lt;/td&gt;
&lt;td&gt;0.68&lt;/td&gt;
&lt;td&gt;0.68&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Precision&lt;/td&gt;
&lt;td&gt;0.34&lt;/td&gt;
&lt;td&gt;0.60&lt;/td&gt;
&lt;td&gt;0.63&lt;/td&gt;
&lt;td&gt;0.55&lt;/td&gt;
&lt;td&gt;0.65&lt;/td&gt;
&lt;td&gt;0.65&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Recall&lt;/td&gt;
&lt;td&gt;0.59&lt;/td&gt;
&lt;td&gt;0.65&lt;/td&gt;
&lt;td&gt;0.66&lt;/td&gt;
&lt;td&gt;0.60&lt;/td&gt;
&lt;td&gt;0.68&lt;/td&gt;
&lt;td&gt;0.68&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;F1&lt;/td&gt;
&lt;td&gt;0.43&lt;/td&gt;
&lt;td&gt;0.59&lt;/td&gt;
&lt;td&gt;0.62&lt;/td&gt;
&lt;td&gt;0.53&lt;/td&gt;
&lt;td&gt;0.64&lt;/td&gt;
&lt;td&gt;0.66&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;However, when we look at results on test data, random forest model performed roughly the same as Xgboost modeling. The accuracy of Random Forest is 0.68, which is much lower than on train data, which indictas potential issues of overfitting. Based on a combination of performance and consistency, we chose Xgboost which has the highest accuracy of 68% with a overall satisfactory performance on all four categories. All F1, recall and precision values are aligned.&lt;/p&gt;
&lt;h2 id=&#34;reason-why-xgboost-outperformed&#34;&gt;Reason why Xgboost outperformed&lt;/h2&gt;
&lt;p&gt;Our results are aligned in practice of various data science competitions and it also makes sense because for a theoretical standpoint.
Xgboost is essentially a very powerful model especially for classification problems. XGBoost stands for extreme gradient boosting. Boosting is an ensemble technique which trains models in sequence rather than training models separately. Each new model will correct the errors made by the previous ones and are added sequentially until no further improvements are available.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;online-ml-real-time-prediction&#34;&gt;Online ML Real-Time Prediction&lt;/h2&gt;
&lt;p&gt;Online real-time prediction is one of the unique features of our data product. I implemented this platform, from designing the initial layout, seraching for best tools to implementation. The backend I decided to use is Flask, because it is lightweight with simple syntax comparing with other backend options, and it is based on Python which has higher popularity in DS field. Moreover, Flask app could be combined with Dash to create fascinating visualization effects, and it integrates perfectly with the dashboard.&lt;/p&gt;
&lt;p&gt;Total of 10 variables are available for users to manually input with descriptions by the side. Five authors features are the top five are featuring protest plot while the rest are features with higher availability to the general public. There are over 80 features in our data and they will be unrealistic for user input every variable. Below is the input section:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./10.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;This was a great opportunity for me to brush-up on web dev skills. I used HTML and CSS for writing the structure and decoration of this interface, and callbacks in Javascript to render the inputs. Here shows a part of code to demonstarte this process.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;server &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; flask.Flask&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;__name__&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
app &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dash.Dash&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;__name__, server&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;server,external_stylesheets&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;external_stylesheets&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;

layout &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; html.Div&lt;span style=&#34;color:#f92672&#34;&gt;([&lt;/span&gt;
    dbc.Container&lt;span style=&#34;color:#f92672&#34;&gt;([&lt;/span&gt;
        dbc.Row&lt;span style=&#34;color:#f92672&#34;&gt;([&lt;/span&gt; dbc.Col&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;html.H1&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Real Time Prediction Serverless App&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;, className&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;mb-2&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;])&lt;/span&gt;,
    dbc.Container&lt;span style=&#34;color:#f92672&#34;&gt;([&lt;/span&gt;
        dbc.Row&lt;span style=&#34;color:#f92672&#34;&gt;([&lt;/span&gt;dbc.Col&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;dbc.Card&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;html.H3&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;children&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Input Features&amp;#39;&lt;/span&gt;,className&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;text-center text-light bg-dark&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;, body&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;dark&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;, className&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;mt-4 mb-4&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)])&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;])&lt;/span&gt;,
    dbc.FormGroup&lt;span style=&#34;color:#f92672&#34;&gt;([&lt;/span&gt;dbc.Label&lt;span style=&#34;color:#f92672&#34;&gt;([&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Binary Input: if insurance type is &amp;#39;medicare&amp;#39; then 1 else 0&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;])&lt;/span&gt;,
        dbc.Input&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;id&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;INSURANCE_Medicare&amp;#34;&lt;/span&gt;,type&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;number&amp;#34;&lt;/span&gt;, placeholder&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Enter or select...&amp;#34;&lt;/span&gt;,min&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;0, max&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;1&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;])&lt;/span&gt;,
 
@app.callback&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;
    Output&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;out&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;children&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;,
    &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;Input&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;show&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;n_clicks&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)]&lt;/span&gt;,
    
    state&lt;span style=&#34;color:#f92672&#34;&gt;=[&lt;/span&gt;State&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Age&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;value&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;,
           State&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Gender&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;value&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;,
           State&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;HeartRate_Mean&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;value&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;,
           State&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Glucose_Mean&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;value&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;,
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Therefore, besides these 10 selected features, I used mode or mean of the rest remaining variables available to public such as age, sex, and heart rate level, etc.There are over 80 features in our data and it will be unrealistic for user to input every variable. Therefore besides these 10 selected features, we use mod or mean of the rest remaining variables.&lt;/p&gt;
&lt;p&gt;There are over 80 features in our data and they will be unrealistic for user input every variable. Therefore besides these 10 selected features, we use mode or meaning of the remaining variables.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./6.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Once the user finished all the required input. Upon clicking the go button our cloud-based model will display the most accurate prediction based on the input. Here we can see that the best gas according to my input is home which means the patient with such features is most likely to be discharged to home.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;my-takeaways-from-this-project&#34;&gt;My takeaways from this project&lt;/h2&gt;
&lt;p&gt;I&amp;rsquo;m really glad to have this great opportunity to work with MIMIC EHR dataset, I have always been intrigued by application of Data Science in biomedical filed and this final project marked a milestone on my trajectory into personal &amp;ldquo;wild west&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;This was a good combination of skills learned in class and real-world challenges, and I feel very satisfied to successfully implement a complete inteface based on ML modeling and analysis. Big shout-out to my teammates for a semester&amp;rsquo;s hard work.üòä Thanks to Prof. Chan and TA for all the precious instructions &amp;amp; suggestions.üéâ&lt;/p&gt;
&lt;p&gt;I hope you&amp;rsquo;re enjoying this blog article and find our data product interesting. Here is the &lt;a href=&#34;https://bios823-mimic-dashboard.ue.r.appspot.com/deploy_app&#34;&gt;Interactive App&lt;/a&gt;. &lt;a href=&#34;https://github.com/biostats823-final-project/MIMIC-Predictive-Modeling&#34;&gt;GitHub Link of models&lt;/a&gt; is here. &lt;a href=&#34;https://github.com/biostats823-final-project/MIMIC-Dashboard&#34;&gt;GitHub Link of dashboard&lt;/a&gt; can be found here.&lt;/p&gt;
&lt;p&gt;Thanks for readingÔºÅ&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;Plotly website &lt;a href=&#34;https://plotly.com/&#34;&gt;https://plotly.com/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep Learning - Insects Classification</title>
      <link>https://yuan-feng1.github.io/project/insect/</link>
      <pubDate>Sun, 14 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://yuan-feng1.github.io/project/insect/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;./0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;introduction-to-cnn&#34;&gt;Introduction to CNN&lt;/h2&gt;
&lt;p&gt;A convolutional neural network (CNN) is a specific type of artificial neural network that uses perceptrons, a machine learning unit algorithm, for supervised learning, to analyze data. CNNs apply to image processing, natural language processing and other kinds of cognitive tasks. They are also the go-to deep learning architecture for computer vision tasks, such as object detection, image segmentation, facial recognition, etc.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;image-classification&#34;&gt;Image Classification&lt;/h2&gt;
&lt;p&gt;Image classification is one of popular use-case for CNN. In this hands-on tutorial, we will leverage Keras, a python based deep learning framework to build the CNN model to classify the type of insects from &lt;a href=&#34;https://www.insectimages.org/index.cfm&#34;&gt;insect images&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Classification is the process of categorizing images based on their features. Theses feature are usually represented by the significant edges in an image, the level of pixel density, the different pixel values, etc. With regard to the insect dataset, the shapes and edges of insects could be different, the colors in pixels values may also vary, and these indicators may help indentify the specific insect images, and we hope to find thses specific pattern across these images by converting them into matrices of pixel values and further feed these data into deep learning models.&lt;/p&gt;
&lt;p&gt;One example of this preprocessing is shown below. After converting the images into matrices of pixels, we could construct the original image with the following code, which will return the first image in train dataset.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt.imshow&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;X_train&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0&lt;span style=&#34;color:#f92672&#34;&gt;][&lt;/span&gt;:,:,::-1&lt;span style=&#34;color:#f92672&#34;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                                                 Figure 1 - Image of Dragonfly
&lt;/code&gt;&lt;/pre&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;img src=&#34;./0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;components-in-cnn&#34;&gt;Components in CNN&lt;/h2&gt;
&lt;p&gt;The workflow is as follows: For each input image in CNN models, it will pass it through a series of convolution layers with filters (Kernals), then the Pooling process, then will pass through fully connected layers (FC) and lastly, apply Softmax function to classify an object, and return the probabilistic values between 0 and 1.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Convolution&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A convolution is a mathematical operation applied on a matrix. This matrix is usually the image represented in the form of pixels/numbers. The convolution operation extracts the features from the image.
&lt;img src=&#34;./1.gif&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                                                 Figure 2 - Convolution Example
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Padding&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Padding is simply a process of adding layers of zeros to our input images so as to avoid the problems mentioned above. This prevents shrinking as, if p = number of layers of zeros added to the border of the image, then our (n x n) image becomes (n + 2p) x (n + 2p) image after padding&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ReLu layer&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The importance of ReLU is to introduce non-linearity in our CNN model. This is an element-wise operation (applied per pixel) which will replaces all negative pixel values by 0 in the feature map. Convolution is a linear operation ‚Äì element wise matrix multiplication and addition, so we account for non-linearity by introducing a non-linear function like ReLU.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pooling&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The reason why we introduce Spatial Pooling (also called subsampling or downsampling) is that it will reduce the dimensionality of each feature map but retains the most important information. Spatial Pooling can be of different types: Max, Average, Sum etc. In case of Max Pooling, we define a spatial neighborhood (for example, a 2√ó2 window) and take the largest element from the rectified feature map within that window. In cases of Average Pooling, we could take the average values, and in case of sum pooling, we will use the sum of all elements in that window. In practice, Max Pooling has been shown to perform the best.
&lt;img src=&#34;./5.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                                                     Figure 2 - Pooling Example
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Fully connected layer&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Then we will flatten the output of the last ReLu layer. (Flattening means we convert it to a vector.) The vector values are then connected to all neurons in the fully connected layer. When the model is able to detect higher level features in the input images, it can then function as an input for a fully connected layer.
&lt;img src=&#34;./6.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                                                     Figure 2 - Fully connected layer Example
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;code-implementation&#34;&gt;Code Implementation&lt;/h2&gt;
&lt;p&gt;Below is the Python keras inplementation of using the insects dataset to classify the type of insects. After pre-processing mentioned previously, we then construct the CNN model and fit the train dataset into the model. Here I use 50 epochs and batch size of 64, and as shown in the screenshot, the accuracy kept increasing as the training proceed.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;  keras.models.Sequential&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Conv2D&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;32, &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;5, 5&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;, input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=(&lt;/span&gt;84,84,3&lt;span style=&#34;color:#f92672&#34;&gt;)))&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;MaxPooling2D&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;pool_size&lt;span style=&#34;color:#f92672&#34;&gt;=(&lt;/span&gt;2, 2&lt;span style=&#34;color:#f92672&#34;&gt;)))&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Conv2D&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;32, &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;5, 5&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;))&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;MaxPooling2D&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;pool_size&lt;span style=&#34;color:#f92672&#34;&gt;=(&lt;/span&gt;2, 2&lt;span style=&#34;color:#f92672&#34;&gt;)))&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Flatten&lt;span style=&#34;color:#f92672&#34;&gt;())&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Dense&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;1000, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;))&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Dropout&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;0.5&lt;span style=&#34;color:#f92672&#34;&gt;))&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Dense&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;500, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;))&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Dropout&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;0.5&lt;span style=&#34;color:#f92672&#34;&gt;))&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Dense&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;250, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;))&lt;/span&gt;
model.add&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Dense&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;10, activation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./3.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Then after the training is completed, the model will be compiled and fit on train dataset. The accuracy on test data is 0.73 and loss is 1.60. These are not optimal as of now, there may be overfitting issues, which could be fixed by further tuning the model and using cross-validation techniques in the future.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;model.compile&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;
              loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;categorical_crossentropy&amp;#39;&lt;/span&gt;,
              metrics&lt;span style=&#34;color:#f92672&#34;&gt;=[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;])&lt;/span&gt;
model.fit&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;X_train, y_train, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;50, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;64&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
test_loss, test_acc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model.evaluate&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;X_test, y_test&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./4.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;sources&#34;&gt;Sources&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://cs231n.github.io/convolutional-networks/&#34;&gt;Convolutional Neural Networks (CNNs / ConvNets)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/&#34;&gt;An Intuitive Explanation of Convolutional Neural Networks&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Star Wars Data with Request</title>
      <link>https://yuan-feng1.github.io/project/starwars/</link>
      <pubDate>Sun, 14 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://yuan-feng1.github.io/project/starwars/</guid>
      <description>&lt;h2 id=&#34;star-wars-api--request&#34;&gt;Star Wars API &amp;amp; Request&lt;/h2&gt;
&lt;p&gt;Requests is one of the most popular libraries that helps retrieve data from the Internet. I will utilize the Star Wars API, which includes information about all characters from Stsr Wars, and Request to collect online data in Python and perform data wrangling and analysis.&lt;/p&gt;
&lt;h2 id=&#34;loading-data-with-request&#34;&gt;Loading Data with Request&lt;/h2&gt;
&lt;h2 id=&#34;heading&#34;&gt;&lt;/h2&gt;
&lt;h2 id=&#34;heading-1&#34;&gt;&lt;/h2&gt;
&lt;p&gt;First, we take a look at Request and download the data of the first person in the database. By giving the link of first person and convert the returned values to json format, we successfully retrieved information about Luke Skywalker.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;import requests
one &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; requests.get&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://swapi.dev/api/people/1&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
char &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; one.json&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt;
char
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./1.jpg&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Notice that the API only returns the information in the current page passed in the request function. In order to retrieve all characters from database, a for loop that iterates over all non-empty pages will be applied.&lt;/p&gt;
&lt;h2 id=&#34;heading-2&#34;&gt;&lt;/h2&gt;
&lt;h2 id=&#34;heading-3&#34;&gt;&lt;/h2&gt;
&lt;h2 id=&#34;heading-4&#34;&gt;&lt;/h2&gt;
&lt;h2 id=&#34;heading-5&#34;&gt;&lt;/h2&gt;
&lt;h2 id=&#34;getting-all-characters-from-star-wars&#34;&gt;Getting All Characters from Star Wars&lt;/h2&gt;
&lt;h2 id=&#34;heading-6&#34;&gt;&lt;/h2&gt;
&lt;h2 id=&#34;heading-7&#34;&gt;&lt;/h2&gt;
&lt;p&gt;The following code shows how to download the information about each person and then transform into a complete list.&lt;/p&gt;
&lt;p&gt;By initiating an empty list and a pending the results of each request to that list, You&amp;rsquo;ll be able to get an entire list of all people appeared in the Star Wars API.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;
instance  &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; requests.get&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;https://swapi.dev/api/people/&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
all &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; instance.json&lt;span style=&#34;color:#f92672&#34;&gt;()[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;next&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;:
    all &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; instance.json&lt;span style=&#34;color:#f92672&#34;&gt;()[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;results&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
    instance &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; requests.get&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;instance.json&lt;span style=&#34;color:#f92672&#34;&gt;()[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;next&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;])&lt;/span&gt;

all &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; instance.json&lt;span style=&#34;color:#f92672&#34;&gt;()[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;results&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In order to better understand the retrieved information, I transformed the J some format into a panda dataframe using the &amp;ldquo;json_normalize&amp;rdquo; function. Below a preview of what the date it looks like.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;import pandas as pd

df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd.json_normalize&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;all&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
df.head&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;./4.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;query-to-find-the-oldest&#34;&gt;Query to Find the Oldest&lt;/h2&gt;
&lt;h2 id=&#34;heading-8&#34;&gt;&lt;/h2&gt;
&lt;h2 id=&#34;heading-9&#34;&gt;&lt;/h2&gt;
&lt;p&gt;Perfect! Now that we have the data set, we can go ahead and start some interesting analysis. Here we hope to find the name of the oldest person.&lt;/p&gt;
&lt;p&gt;In the world of Star Wars, the way they record the time is by ABY or BBY, which means ‚ÄúAfter Battle of Yavin‚Äù / ‚ÄúBefore Battle of Yavin‚Äù. We do not need to worry about this, because all people in our dataset are classified as BBY.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;birth &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;birth_year&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
import numpy as np
birth &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; birth.str.replace&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;BBY&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;.replace&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;unknown&amp;#39;&lt;/span&gt;,0&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;.astype&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
df&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;age&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; birth
df.sort_values&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;by&lt;span style=&#34;color:#f92672&#34;&gt;=[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;, ascending&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;.head&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;1&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then we could do a simple data cleaning by removing the BBY in the &amp;ldquo;age&amp;rdquo; columnm, transform string formatted numbers into double, and replace missing values with 0.Lastly, by performing a sort on the age column in a descending fashion, you&amp;rsquo;ll get the line of the olderst person - Yoda! that explains why he is so wise.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./5.jpg&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;what-movies-does-he-appear-in&#34;&gt;What Movies Does He Appear in?&lt;/h2&gt;
&lt;h2 id=&#34;heading-10&#34;&gt;&lt;/h2&gt;
&lt;h2 id=&#34;heading-11&#34;&gt;&lt;/h2&gt;
&lt;p&gt;Now that we have Yoda, As somebody who has never watch Star Wars movies before, I am really interested in finding out what movies he appeared in. However, our current dataset only shows a list of available urls to retrieve the films information. So we need to construct a for loop, and then use request to get the title from the information retrieved using these URLs.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;films &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;x &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; x in df.sort_values&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;by&lt;span style=&#34;color:#f92672&#34;&gt;=[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;age&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;, ascending&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;.head&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;1&lt;span style=&#34;color:#f92672&#34;&gt;)[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;films&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]][&lt;/span&gt;0&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
film_names &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;requests.get&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;i&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;.json&lt;span style=&#34;color:#f92672&#34;&gt;()[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;title&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i in films&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
film_names
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;I also concatenated all the responses into a list. We can see that Yoda appeared in The Empire Strikes Back, Return of the Jedi, The Phantom Menace, Attack of the Clones, and Revenge of the Sith.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./3.jpg&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;If you want to find out more about the process in detail. Here is detailed process ans source code on my &lt;a href=&#34;https://github.com/yuan-feng1/bios-823-2019/blob/master/HW5.ipynb&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Transfer Learning Tutorial</title>
      <link>https://yuan-feng1.github.io/project/tranfer/</link>
      <pubDate>Sun, 14 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://yuan-feng1.github.io/project/tranfer/</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;This tutorial explains the concepts and motivations behind transfer learning and seeks to provide an example of the technique used in practice based on my unerstanding and experience.&lt;/p&gt;
&lt;p&gt;In the supervised learning context, deep neural networks have become more and more accurate in recent years. Convolutional neural networks using a residual learning network are particularly good at finding the optimal model parameters while improving accuracy. However, it is not possible to apply these deep models into a different situation or phenomena other than what they were trained and designed for. It is important to have this flexibility in real-world scenarios where we rarely encounter data structured in the same way as our training data. Transfer learning allows us to transfer some of the information learned from an ideal situation into a different and related situation for which our data is more limited.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./d1.png&#34; alt=&#34;png&#34;&gt;                      &lt;br&gt;
Above are sample images from the hymenoptera_data dataset. In this article we will define a common transfer learning technique for computer vision and image classification problem: inductive transfer learning using feature extraction or embedding using the hymenoptera_data dataset. By using a model previously trained on a robust training dataset, we can take advantage of its optimal parameters as a way to extract features for new data, reducing training time and improving performance considerably. First, we shall implement this method classically. Later, we will discuss one particular cutting-edge approach to this problem using quantum computing for a hybrid transfer learning method. In this approach, we replace a neural network‚Äôs output layer with a dressed quantum circuit that we then train for our target domain and task.&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;Here is the model performance:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./d2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Transfer learning techniques can improve significantly on similar models built from scratch. Training time can be reduced by one half with classical parameter transfer methods, and performance in terms of AUC, AP and accuracy can also be improved significantly. These results can be attained with a minimum amount of training data as long as there is a pre-existing model trained in a similar domain. Both the classical and the CQ hybrid approach accomplished very similar performance in terms of accuracy and AUC. This both highlights the advantages of transfer learning and positive outlook of novel quantum methods to perform classifications.&lt;/p&gt;
&lt;p&gt;The project report can be found &lt;a href=&#34;https://github.com/yuanfeng2/Transfer_Learning_Tutorial&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Spotify Song Database</title>
      <link>https://yuan-feng1.github.io/project/spotify/</link>
      <pubDate>Sat, 13 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://yuan-feng1.github.io/project/spotify/</guid>
      <description>&lt;h2 id=&#34;spotify-songs-data&#34;&gt;Spotify Songs Data&lt;/h2&gt;
&lt;p&gt;Understanding and managing data is one of the priorities of analysts and data scientists. Relational databases are common and useful tools for performing tasks in selected database. Both querying and building databases are essential functionaries of relational databases. This post will focus on constructing databases in SQL with data from &lt;a href=&#34;https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-01-21/readme.md&#34;&gt;Spotify songs&lt;/a&gt;. Various information including track name, album name and track characteristics are provided in this dataset. Analysis will be also performed on the intrumentalness of songs in playlists.&lt;/p&gt;
&lt;h2 id=&#34;database-basics&#34;&gt;Database Basics&lt;/h2&gt;
&lt;p&gt;In order for databased to run efficiently, normalization is a common technique to reduce redundancy in storaging the information.  Normalization derives the relationships of contents and stores the dataset in separate tables.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;First Normal Form (1NF)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is the basic requirement for database efficiency where we require four must-have features: Each column name is unique; Atomic values in each cell; The values in one column should belong to one type and the order does not matter.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Second Normal Form (2NF)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We then come to Second Normal Form where there are more requirements based on 1NF: Now no partial dependency is allowed. It means that there cannot be dependencies other than the Primary Key, which is a set of values that could uniquely identify a record. And we must find each value based on the complete Primary Key.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Third Normal Form (3NF)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In 3NF, besides 1NF and 2NF requirements, we are not allowed to have transitive dependencies: Non-Primary Key columns in the data cannot contain information about the rest of columns.&lt;/p&gt;
&lt;h2 id=&#34;our-schema&#34;&gt;Our Schema&lt;/h2&gt;
&lt;p&gt;If we know the track ID, we could find its name, release date and artist. And based on the track name, we will then find about album name, album release date, etc. Therefore, the best schema is to separate them into different tables to achieve Third Normal Form:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Table&lt;/th&gt;
&lt;th&gt;Columns Included&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;track_id_playlist_id&lt;/td&gt;
&lt;td&gt;Track ID and Playlist ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;track_id_album_id&lt;/td&gt;
&lt;td&gt;Track ID and Album ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;playlist_id_album_id&lt;/td&gt;
&lt;td&gt;Playlist ID and Album ID&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;album_id_album_name&lt;/td&gt;
&lt;td&gt;Album ID and Album Name&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;album_id_album_date&lt;/td&gt;
&lt;td&gt;Album ID and Release Date&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;playlist_id_name&lt;/td&gt;
&lt;td&gt;Playlist ID and Name&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;playlist_id_genre&lt;/td&gt;
&lt;td&gt;Playlist ID and Genre&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;playlist_id_subgenre&lt;/td&gt;
&lt;td&gt;Playlist ID and Subgenre&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;track_id_track_name&lt;/td&gt;
&lt;td&gt;Track ID and Track names&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;track_id_track_artist&lt;/td&gt;
&lt;td&gt;Track ID and artist names&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;track_id_more_details&lt;/td&gt;
&lt;td&gt;Track ID and other features&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;database-constrcution&#34;&gt;Database Constrcution&lt;/h2&gt;
&lt;p&gt;With the help of SQLite, database construction is now an easy process, we can connect to the server using just a few lines of code and upload dataframes directly into the created database:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;%load_ext sql
%sql sqlite://
%sql PERSIST track_id_album_id;
%sql PERSIST track_id_playlist_id;
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here is detailed process ans source code on my &lt;a href=&#34;https://github.com/yuan-feng1/bios-823-2019/blob/master/Yuan_Feng_HW4.ipynb&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;database-test-run&#34;&gt;Database Test Run&lt;/h2&gt;
&lt;p&gt;We can test the functionality of the database by running some queries to solve a question of our interest. Here we want to see find the names of all playlists that contain instrumentals.&lt;/p&gt;
&lt;p&gt;Based on the data dictionary, we know songs with &amp;ldquo;instrumentals&amp;rdquo; bigger than .5 are qualified for this question. To find the names of such playlists, we need information from
&amp;ldquo;track_id_playlist_id&amp;rdquo;, &amp;ldquo;track_id_more_details&amp;rdquo; and &amp;ldquo;playlist_id_name&amp;rdquo;. The following code first selects playlist ID that has instrumental songs and saves as temporary table, then join the &amp;ldquo;playlist_name&amp;rdquo; table to find the names corresponding with these track IDs.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;%%sql 
create table temp as
&lt;span style=&#34;color:#66d9ef&#34;&gt;select&lt;/span&gt; distinct&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;p.playlist_id&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
from track_id_playlist_id as p 
left join track_id_more_details as t
on t.track_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; p.track_id
where t.instrumentalness &amp;gt; 0.5;

&lt;span style=&#34;color:#66d9ef&#34;&gt;select&lt;/span&gt; distinct&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;p.playlist_name&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
from temp
left join playlist_id_name as p 
on p.playlist_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; temp.playlist_id

DROP TABLE IF EXISTS temp;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now our database is successfully implemented! As we could see below, the code will return a list of all playlists that contain instrumentals, which means it&amp;rsquo;s running as expected:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./res.jpg&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
